{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0147a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a190fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dba0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Set up path\n",
    "if os.getcwd() == '/content':\n",
    "    %cd '/content/drive/MyDrive/Colab Notebooks/kaggle/Player-Contact-Detection/tutorial'\n",
    "    base_path = Path('__file__').resolve().parent.parent\n",
    "else:\n",
    "    base_path = Path().resolve()\n",
    "\n",
    "data_path = base_path / 'data'\n",
    "submission_path = base_path / 'submission'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd952fbb",
   "metadata": {},
   "source": [
    "# Load Fully-Connected train-test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0c44c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(data_path / 'sample_submission.csv')\n",
    "\n",
    "def make_filename(windows: int=0, test: bool=False, ground: bool=False):\n",
    "    train_test = 'test' if test else 'train'\n",
    "    type_ = 'ground' if ground else 'player'\n",
    "\n",
    "    filename = f'{train_test}_{type_}_contact_tracking'\n",
    "\n",
    "    if windows == 0:\n",
    "        suffix = '.csv'\n",
    "    elif windows >= 1:\n",
    "        suffix = f'_{windows}.csv'\n",
    "\n",
    "    return filename + suffix\n",
    "\n",
    "def load_data(data_path, windows: int=0, ground: bool=False):\n",
    "    train_filename = make_filename(windows, test=False, ground=ground)\n",
    "    test_filename = make_filename(windows, test=True, ground=ground)\n",
    "\n",
    "    try:\n",
    "        train = pd.read_csv(data_path / train_filename)\n",
    "        test = pd.read_csv(data_path / test_filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Return basic dataset.\")\n",
    "        load_data(data_path, 0)\n",
    "        \n",
    "    train.sort_values(by=['group_id', 'step'], inplace=True)\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    test.sort_values(by=['group_id', 'step'], inplace=True)\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06800374",
   "metadata": {},
   "source": [
    "# Imbalance Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1982de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    temp = data.loc[data.contact == 1]\n",
    "    index = temp.index.values.tolist()\n",
    "\n",
    "    prev_i = index[0]\n",
    "    group_ids = []\n",
    "\n",
    "    for i in index:\n",
    "        if (i - prev_i) > 1:\n",
    "            sr = data.loc[prev_i,:]\n",
    "            group_id = sr.loc['group_id']\n",
    "            group_ids.append(group_id)\n",
    "        prev_i = i\n",
    "    \n",
    "    drop_cols = ['contact_id', 'group_id', 'game_play',\n",
    "                 'step', 'nfl_player_id_1', 'nfl_player_id_2']\n",
    "\n",
    "    result = data.loc[data.group_id.isin(group_ids), :]\n",
    "    result.drop(columns=drop_cols, inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d93395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    temp = data.loc[data.contact == 1]\n",
    "    index = temp.index.values.tolist()\n",
    "\n",
    "    prev_i = index[0]\n",
    "    group_ids = []\n",
    "\n",
    "    for i in index:\n",
    "        if (i - prev_i) > 1:\n",
    "            sr = data.loc[prev_i,:]\n",
    "            group_id = sr.loc['group_id']\n",
    "            group_ids.append(group_id)\n",
    "        prev_i = i\n",
    "    \n",
    "    drop_cols = ['contact_id', 'group_id', 'game_play',\n",
    "                 'step', 'nfl_player_id_1', 'nfl_player_id_2']\n",
    "\n",
    "    result = data.loc[data.group_id.isin(group_ids), :]\n",
    "    result.drop(columns=drop_cols, inplace=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3bbe2",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8eeb21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim # d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cebd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embedding_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
    "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac014cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        max_len = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e24563a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m  \u001b[38;5;66;03m# 빈도수 상위 2만개의 단어만 사용\u001b[39;00m\n\u001b[1;32m      2\u001b[0m max_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m11\u001b[39m  \u001b[38;5;66;03m# 문장의 최대 길이\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m훈련용 리뷰 개수 : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(\u001b[43mX_train\u001b[49m)))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m테스트용 리뷰 개수 : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(X_train)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_size = 128  # 빈도수 상위 2만개의 단어만 사용\n",
    "max_len = 11  # 문장의 최대 길이\n",
    "\n",
    "# print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n",
    "# print('테스트용 리뷰 개수 : {}'.format(len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45997828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer():\n",
    "    embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n",
    "    num_heads = 2  # 어텐션 헤드의 수\n",
    "    dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
    "\n",
    "    inputs = tf.keras.layers.Input(shape=(max_len,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
    "    x = embedding_layer(inputs)\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(filters = 64, kernel_size = 2, padding='valid', activation='relu')(x)\n",
    "    x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "    #print(x.shape)\n",
    "    #transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
    "    transformer_block = TransformerBlock(64, num_heads, dff)\n",
    "    x = transformer_block(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    #x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    outputs = tf.keras.layers.Dense(3, activation=\"softmax\")(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    adam = tf.optimizers.Adam(learning_rate = 0.001)\n",
    "    model.compile(optimizer = adam, loss = \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea3d1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_result(train: pd.DataFrame, test: pd.DataFrame,\n",
    "                 windows: int, save: bool=False) -> pd.DataFrame:\n",
    "    drop_cols = ['contact_id', 'group_id', 'game_play',\n",
    "                 'step', 'nfl_player_id_1', 'nfl_player_id_2']\n",
    "    target_column = 'contact'\n",
    "\n",
    "    X = train.drop(columns=[target_column])\n",
    "    y = train.contact\n",
    "    X_test = test.drop(columns=drop_cols + [target_column])\n",
    "\n",
    "    # train, validation dataset split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=42)\n",
    "\n",
    "    # model initializing\n",
    "    model = KerasClassifier(build_fn=transformer, epochs=90, batch_size=32, verbose=0)\n",
    "    model._estimator_type=\"classifier\"\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    # model training\n",
    "    model.fit(X_train, y_train, batch_size=1024, epochs=2000)\n",
    "    \n",
    "    # Find optimized parameters(batch size and epochs)\n",
    "    params = {\n",
    "    'batch_size':[16, 32],\n",
    "    'epochs':[60, 80, 90, 120, 150],\n",
    "    }\n",
    "    \n",
    "    grid = GridSearchCV(model, param_grid=params, cv=3, refit=True)\n",
    "    grid.fit(X_train, train_y)\n",
    "    \n",
    "    # prediction\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # scoring\n",
    "#     score_train = clf.score(y_train, y_train_pred)\n",
    "#     score_val = clf.score(y_val, y_pred)\n",
    "#     print(\"Train %s score is %.4f\" % (clf.metric_, score_train))\n",
    "#     print(\"Validation %s score is %.4f\" % (clf.metric_, score_val))\n",
    "    score_train = mcc(y_train, y_train_pred)\n",
    "    score_val = mcc(y_val, y_pred)\n",
    "    print(\"Train mcc score is %.4f\" % (score_train))\n",
    "    print(\"Validation mcc score is %.4f\" % (score_val))\n",
    "\n",
    "    y_test = clf.predict(X_test)\n",
    "\n",
    "    test.loc[:, target_column] = y_test\n",
    "    return test.loc[:, ['contact_id', target_column]], score_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091631e",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b25a2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(windows):\n",
    "    train_player, test_player = load_data(data_path, windows, ground=False)\n",
    "    train_ground, test_ground = load_data(data_path, windows, ground=True)\n",
    "\n",
    "    train_player_balanced = preprocessing(train_player)\n",
    "    train_ground_balanced = preprocessing(train_ground)\n",
    "\n",
    "    print(f'#----------------- Windows: {str(windows): <2s}-------------------#')\n",
    "    print('#------ Model: contact between players -----#')\n",
    "    player, score_player = model_result(train_player_balanced, test_player, windows)\n",
    "    print()\n",
    "    print('#------ Model: contact player-ground -------#')\n",
    "    ground, score_ground = model_result(train_ground_balanced, test_ground, windows)\n",
    "    print('#-------------------------------------------------#')\n",
    "    print()\n",
    "    score_ls.append((score_player, score_ground))\n",
    "    submission = pd.merge(submission.loc[:, 'contact_id'],\n",
    "                          pd.concat([test_player, test_ground]),\n",
    "                          on='contact_id', how='left')\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc0084",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efd87572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission(submission, windows):\n",
    "    num = 1\n",
    "    try:\n",
    "        for filename in os.listdir(submission_path):\n",
    "            if filename.contains(f'submission_win{windows}'):\n",
    "                num += 1\n",
    "    except FileNotFoundError:\n",
    "        num = 1\n",
    "\n",
    "    filename = f'submission_win{windows}_ver{num}.csv'\n",
    "    submission.to_csv(base_path / 'submission' / filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45caa124",
   "metadata": {},
   "source": [
    "# Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12537b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/_5h82f8n3pz9ll_43q6tphvw0000gn/T/ipykernel_19716/1953976632.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.drop(columns=drop_cols, inplace=True)\n",
      "/var/folders/4d/_5h82f8n3pz9ll_43q6tphvw0000gn/T/ipykernel_19716/1953976632.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result.drop(columns=drop_cols, inplace=True)\n",
      "/var/folders/4d/_5h82f8n3pz9ll_43q6tphvw0000gn/T/ipykernel_19716/2554853103.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=transformer, epochs=90, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------- Windows: 0 -------------------#\n",
      "#------ Model: contact between players -----#\n",
      "(213884, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-07 19:21:34.041733: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "window = 0\n",
    "submission = inference(window)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cbbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
